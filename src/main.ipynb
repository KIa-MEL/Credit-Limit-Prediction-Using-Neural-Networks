{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The dataset is shown below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../data/CreditPrediction.csv')\n",
    "# removing duplicated datas\n",
    "data_no_dup = data_df.drop_duplicates() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_values(df):\n",
    "    # Identify numerical and categorical columns\n",
    "    num_cols = df.select_dtypes(exclude='object').columns\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "    # Create transformers for numerical and categorical data\n",
    "    num_transformer = IterativeImputer()\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Combine transformers into a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols),\n",
    "            ('cat', cat_transformer, cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply the transformations\n",
    "    preprocessed_data = preprocessor.fit_transform(data_no_dup)\n",
    "\n",
    "    # Convert the result back to a DataFrame (optional)\n",
    "    preprocessed_df = pd.DataFrame(preprocessed_data)\n",
    "\n",
    "    # Display the preprocessed DataFrame\n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_no_dup.drop('Credit_Limit', axis=1)\n",
    "y = data_no_dup['Credit_Limit']\n",
    "\n",
    "X = fix_missing_values(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.000000\n",
      "Feature 1: 0.008512\n",
      "Feature 2: 0.000000\n",
      "Feature 3: 0.000000\n",
      "Feature 4: 0.008835\n",
      "Feature 5: 0.000331\n",
      "Feature 6: 0.000000\n",
      "Feature 7: 0.132683\n",
      "Feature 8: 0.013488\n",
      "Feature 9: 0.115319\n",
      "Feature 10: 0.056835\n",
      "Feature 11: 0.003806\n",
      "Feature 12: 0.785917\n",
      "Feature 13: 0.120282\n",
      "Feature 14: 0.116853\n",
      "Feature 15: 0.008417\n",
      "Feature 16: 0.000000\n",
      "Feature 17: 0.000000\n",
      "Feature 18: 0.001005\n",
      "Feature 19: 0.000000\n",
      "Feature 20: 0.000000\n",
      "Feature 21: 0.002452\n",
      "Feature 22: 0.002436\n",
      "Feature 23: 0.005893\n",
      "Feature 24: 0.010007\n",
      "Feature 25: 0.000000\n",
      "Feature 26: 0.051916\n",
      "Feature 27: 0.029860\n",
      "Feature 28: 0.017966\n",
      "Feature 29: 0.050497\n",
      "Feature 30: 0.145395\n",
      "Feature 31: 0.006149\n",
      "Feature 32: 0.091583\n",
      "Feature 33: 0.026589\n",
      "Feature 34: 0.000000\n",
      "Feature 35: 0.065859\n",
      "12\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAjcElEQVR4nO3dfWzV5f3/8deh2FOG9jgpnLZSSqOClSrT04kt1m2oZ6vOSFy0SgKorbPzLrXqQtdMXKMpX+e6smkrRNAxURsHLibUm5OMm0JnIk2J/IA5N8BT8dSudTsHcZ7Ocv3+YJzv99AWekrp1XP6fCRX4rl6Xee8r1xH+/I6n36OwxhjBAAAYMkE2wUAAIDxjTACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwKqJtgsYiqNHj+rTTz/VOeecI4fDYbscAAAwBMYYHT58WJmZmZowYfDzj7gII59++qmysrJslwEAAIaho6ND06dPH/TncRFGzjnnHEnHFpOammq5GgAAMBShUEhZWVmR3+ODiYswcvyjmdTUVMIIAABx5lSXWHABKwAAsIowAgAArCKMAAAAqwgjAADAqmGFkYaGBuXk5CglJUUej0ctLS0nHb9+/XrNnTtX3/jGN5SRkaG77rpLPT09wyoYAAAklpjDSFNTkyoqKlRdXa329nYVFRWpuLhYfr9/wPHbt2/XkiVLVFpaqj179uj111/X+++/r7KystMuHgAAxL+Yw0hdXZ1KS0tVVlam3Nxc1dfXKysrS42NjQOOf++99zRz5kw99NBDysnJ0dVXX617771XO3fuPO3iAQBA/IspjPT29qqtrU1erzeq3+v1qrW1dcA5hYWF+uSTT9Tc3CxjjD777DP94Q9/0I033jjo64TDYYVCoagGAAASU0xhpLu7W319fXK73VH9brdbnZ2dA84pLCzU+vXrVVJSouTkZKWnp+vcc8/Vb3/720Ffp7a2Vi6XK9K4FTwAAIlrWBewnngnNWPMoHdX27t3rx566CE9/vjjamtr09tvv60DBw6ovLx80OevqqpSMBiMtI6OjuGUCQAA4kBMt4NPS0tTUlJSv1OQrq6ufqclx9XW1mr+/Pl67LHHJEmXXXaZJk+erKKiIj355JPKyMjoN8fpdMrpdMZSGgAAiFMxnYwkJyfL4/HI5/NF9ft8PhUWFg4458svv+z3tcFJSUmSjp2oAACA8S3mj2kqKyv1wgsvaO3atdq3b58efvhh+f3+yMcuVVVVWrJkSWT8TTfdpI0bN6qxsVH79+/Xjh079NBDD+nKK69UZmbmyK0EAADEpZi/tbekpEQ9PT2qqalRIBBQXl6empublZ2dLUkKBAJR9xy58847dfjwYT377LN65JFHdO6552rBggX6n//5n5FbBQAAiFsOEweflYRCIblcLgWDQaWmptouBxiymcs2DWncwRWD/6k7AMSrof7+5rtpAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYNWwwkhDQ4NycnKUkpIij8ejlpaWQcfeeeedcjgc/dqcOXOGXTQAAEgcMYeRpqYmVVRUqLq6Wu3t7SoqKlJxcbH8fv+A41euXKlAIBBpHR0dOu+883TrrbeedvEAACD+xRxG6urqVFpaqrKyMuXm5qq+vl5ZWVlqbGwccLzL5VJ6enqk7dy5U//85z911113nXbxAAAg/sUURnp7e9XW1iav1xvV7/V61draOqTnWLNmja677jplZ2cPOiYcDisUCkU1AACQmGIKI93d3err65Pb7Y7qd7vd6uzsPOX8QCCgt956S2VlZScdV1tbK5fLFWlZWVmxlAkAAOLIsC5gdTgcUY+NMf36BvLSSy/p3HPP1cKFC086rqqqSsFgMNI6OjqGUyYAAIgDE2MZnJaWpqSkpH6nIF1dXf1OS05kjNHatWu1ePFiJScnn3Ss0+mU0+mMpTQAABCnYjoZSU5Olsfjkc/ni+r3+XwqLCw86dytW7fqb3/7m0pLS2OvEgAAJKyYTkYkqbKyUosXL1Z+fr4KCgq0evVq+f1+lZeXSzr2EcuhQ4e0bt26qHlr1qzRvHnzlJeXNzKVAwCAhBBzGCkpKVFPT49qamoUCASUl5en5ubmyF/HBAKBfvccCQaD2rBhg1auXDkyVQMAgIThMMYY20WcSigUksvlUjAYVGpqqu1ygCGbuWzTkMYdXHHjGa4EAEbfUH9/8900AADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwKphhZGGhgbl5OQoJSVFHo9HLS0tJx0fDodVXV2t7OxsOZ1OXXDBBVq7du2wCgYAAIllYqwTmpqaVFFRoYaGBs2fP1+rVq1ScXGx9u7dqxkzZgw457bbbtNnn32mNWvW6MILL1RXV5e+/vrr0y4eAADEP4cxxsQyYd68ebriiivU2NgY6cvNzdXChQtVW1vbb/zbb7+t22+/Xfv379d55503rCJDoZBcLpeCwaBSU1OH9RyADTOXbRrSuIMrbjzDlQDA6Bvq7++YPqbp7e1VW1ubvF5vVL/X61Vra+uAc958803l5+fr6aef1vnnn69Zs2bp0Ucf1b///e9YXhoAACSomD6m6e7uVl9fn9xud1S/2+1WZ2fngHP279+v7du3KyUlRW+88Ya6u7t133336fPPPx/0upFwOKxwOBx5HAqFYikTAADEkWFdwOpwOKIeG2P69R139OhRORwOrV+/XldeeaVuuOEG1dXV6aWXXhr0dKS2tlYulyvSsrKyhlMmAACIAzGFkbS0NCUlJfU7Benq6up3WnJcRkaGzj//fLlcrkhfbm6ujDH65JNPBpxTVVWlYDAYaR0dHbGUCQAA4khMYSQ5OVkej0c+ny+q3+fzqbCwcMA58+fP16effqovvvgi0vfXv/5VEyZM0PTp0wec43Q6lZqaGtUAAEBiivljmsrKSr3wwgtau3at9u3bp4cfflh+v1/l5eWSjp1qLFmyJDJ+0aJFmjJliu666y7t3btX27Zt02OPPaa7775bkyZNGrmVAACAuBTzfUZKSkrU09OjmpoaBQIB5eXlqbm5WdnZ2ZKkQCAgv98fGX/22WfL5/PpwQcfVH5+vqZMmaLbbrtNTz755MitAgAAxK2Y7zNiA/cZQbziPiMAxrMzcp8RAACAkUYYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYNK4w0NDQoJydHKSkp8ng8amlpGXTsli1b5HA4+rW//OUvwy4aAAAkjpjDSFNTkyoqKlRdXa329nYVFRWpuLhYfr//pPM+/PBDBQKBSLvooouGXTQAAEgcMYeRuro6lZaWqqysTLm5uaqvr1dWVpYaGxtPOm/atGlKT0+PtKSkpGEXDQAAEkdMYaS3t1dtbW3yer1R/V6vV62trSede/nllysjI0PXXnutNm/efNKx4XBYoVAoqgEAgMQUUxjp7u5WX1+f3G53VL/b7VZnZ+eAczIyMrR69Wpt2LBBGzdu1OzZs3Xttddq27Ztg75ObW2tXC5XpGVlZcVSJgAAiCMThzPJ4XBEPTbG9Os7bvbs2Zo9e3bkcUFBgTo6OvTMM8/ommuuGXBOVVWVKisrI49DoRCBBACABBXTyUhaWpqSkpL6nYJ0dXX1Oy05mauuukofffTRoD93Op1KTU2NagAAIDHFFEaSk5Pl8Xjk8/mi+n0+nwoLC4f8PO3t7crIyIjlpQEAQIKK+WOayspKLV68WPn5+SooKNDq1avl9/tVXl4u6dhHLIcOHdK6deskSfX19Zo5c6bmzJmj3t5evfzyy9qwYYM2bNgwsisBAABxKeYwUlJSop6eHtXU1CgQCCgvL0/Nzc3Kzs6WJAUCgah7jvT29urRRx/VoUOHNGnSJM2ZM0ebNm3SDTfcMHKrAAAAccthjDG2iziVUCgkl8ulYDDI9SOIKzOXbRrSuIMrbjzDlQDA6Bvq72++mwYAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWDSuMNDQ0KCcnRykpKfJ4PGppaRnSvB07dmjixIn61re+NZyXBQAACSjmMNLU1KSKigpVV1ervb1dRUVFKi4ult/vP+m8YDCoJUuW6Nprrx12sQAAIPHEHEbq6upUWlqqsrIy5ebmqr6+XllZWWpsbDzpvHvvvVeLFi1SQUHBsIsFAACJJ6Yw0tvbq7a2Nnm93qh+r9er1tbWQee9+OKL+vvf/67ly5cP6XXC4bBCoVBUAwAAiSmmMNLd3a2+vj653e6ofrfbrc7OzgHnfPTRR1q2bJnWr1+viRMnDul1amtr5XK5Ii0rKyuWMgEAQBwZ1gWsDocj6rExpl+fJPX19WnRokX6xS9+oVmzZg35+auqqhQMBiOto6NjOGUCAIA4MLSjiv9KS0tTUlJSv1OQrq6ufqclknT48GHt3LlT7e3teuCBByRJR48elTFGEydO1LvvvqsFCxb0m+d0OuV0OmMpDQAAxKmYTkaSk5Pl8Xjk8/mi+n0+nwoLC/uNT01N1e7du7Vr165IKy8v1+zZs7Vr1y7Nmzfv9KoHAABxL6aTEUmqrKzU4sWLlZ+fr4KCAq1evVp+v1/l5eWSjn3EcujQIa1bt04TJkxQXl5e1Pxp06YpJSWlXz8AABifYg4jJSUl6unpUU1NjQKBgPLy8tTc3Kzs7GxJUiAQOOU9RwAAAI5zGGOM7SJOJRQKyeVyKRgMKjU11XY5wJDNXLZpSOMOrrjxDFcCAKNvqL+/+W4aAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFhFGAEAAFYRRgAAgFWEEQAAYBVhBAAAWDWsMNLQ0KCcnBylpKTI4/GopaVl0LHbt2/X/PnzNWXKFE2aNEkXX3yxfv3rXw+7YAAAkFgmxjqhqalJFRUVamho0Pz587Vq1SoVFxdr7969mjFjRr/xkydP1gMPPKDLLrtMkydP1vbt23Xvvfdq8uTJ+vGPfzwiiwAAAPHLYYwxsUyYN2+errjiCjU2Nkb6cnNztXDhQtXW1g7pOW655RZNnjxZv//974c0PhQKyeVyKRgMKjU1NZZyAatmLts0pHEHV9x4hisBgNE31N/fMX1M09vbq7a2Nnm93qh+r9er1tbWIT1He3u7Wltb9Z3vfGfQMeFwWKFQKKoBAIDEFFMY6e7uVl9fn9xud1S/2+1WZ2fnSedOnz5dTqdT+fn5uv/++1VWVjbo2NraWrlcrkjLysqKpUwAABBHhnUBq8PhiHpsjOnXd6KWlhbt3LlTzz//vOrr6/Xqq68OOraqqkrBYDDSOjo6hlMmAACIAzFdwJqWlqakpKR+pyBdXV39TktOlJOTI0m69NJL9dlnn+mJJ57QHXfcMeBYp9Mpp9MZS2kAACBOxXQykpycLI/HI5/PF9Xv8/lUWFg45OcxxigcDsfy0gAAIEHF/Ke9lZWVWrx4sfLz81VQUKDVq1fL7/ervLxc0rGPWA4dOqR169ZJkp577jnNmDFDF198saRj9x155pln9OCDD47gMgAAQLyKOYyUlJSop6dHNTU1CgQCysvLU3Nzs7KzsyVJgUBAfr8/Mv7o0aOqqqrSgQMHNHHiRF1wwQVasWKF7r333pFbBQAAiFsx32fEBu4zgnjFfUYAjGdn5D4jAAAAI40wAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwaVhhpaGhQTk6OUlJS5PF41NLSMujYjRs36vrrr9fUqVOVmpqqgoICvfPOO8MuGAAAJJaYw0hTU5MqKipUXV2t9vZ2FRUVqbi4WH6/f8Dx27Zt0/XXX6/m5ma1tbXpe9/7nm666Sa1t7efdvEAACD+OYwxJpYJ8+bN0xVXXKHGxsZIX25urhYuXKja2tohPcecOXNUUlKixx9/fEjjQ6GQXC6XgsGgUlNTYykXsGrmsk1DGndwxY1nuBIAGH1D/f0d08lIb2+v2tra5PV6o/q9Xq9aW1uH9BxHjx7V4cOHdd555w06JhwOKxQKRTUAAJCYYgoj3d3d6uvrk9vtjup3u93q7Owc0nP86le/0pEjR3TbbbcNOqa2tlYulyvSsrKyYikTAADEkWFdwOpwOKIeG2P69Q3k1Vdf1RNPPKGmpiZNmzZt0HFVVVUKBoOR1tHRMZwyAQBAHJgYy+C0tDQlJSX1OwXp6urqd1pyoqamJpWWlur111/Xddddd9KxTqdTTqczltIAAECciulkJDk5WR6PRz6fL6rf5/OpsLBw0Hmvvvqq7rzzTr3yyiu68UYu1AMAAP8rppMRSaqsrNTixYuVn5+vgoICrV69Wn6/X+Xl5ZKOfcRy6NAhrVu3TtKxILJkyRKtXLlSV111VeRUZdKkSXK5XCO4FAAAEI9iDiMlJSXq6elRTU2NAoGA8vLy1NzcrOzsbElSIBCIuufIqlWr9PXXX+v+++/X/fffH+lfunSpXnrppdNfAQAAiGsx32fEBu4zgnjFfUYAjGdn5D4jAAAAI40wAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKsIIwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwaqLtAgAAOJNmLts0pHEHV9x4hivBYDgZAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABW8dc0OOO4kh0AcDKcjAAAAKsIIwAAwCrCCAAAsIowAgAArOICVmAM4WJfAOMRJyMAAMAqTkaAOMdpCoB4RxhBQuAXMgDELz6mAQAAVg0rjDQ0NCgnJ0cpKSnyeDxqaWkZdGwgENCiRYs0e/ZsTZgwQRUVFcOtFQAAJKCYw0hTU5MqKipUXV2t9vZ2FRUVqbi4WH6/f8Dx4XBYU6dOVXV1tebOnXvaBQMAgMQScxipq6tTaWmpysrKlJubq/r6emVlZamxsXHA8TNnztTKlSu1ZMkSuVyu0y4YAAAklpjCSG9vr9ra2uT1eqP6vV6vWltbR6yocDisUCgU1QAAQGKKKYx0d3err69Pbrc7qt/tdquzs3PEiqqtrZXL5Yq0rKysEXtuAAAwtgzrAlaHwxH12BjTr+90VFVVKRgMRlpHR8eIPTcAABhbYrrPSFpampKSkvqdgnR1dfU7LTkdTqdTTqdzxJ4PAACMXTGdjCQnJ8vj8cjn80X1+3w+FRYWjmhhAABgfIj5DqyVlZVavHix8vPzVVBQoNWrV8vv96u8vFzSsY9YDh06pHXr1kXm7Nq1S5L0xRdf6B//+Id27dql5ORkXXLJJSOzCgAALBrqXaAl7gQ9kJjDSElJiXp6elRTU6NAIKC8vDw1NzcrOztb0rGbnJ14z5HLL7888s9tbW165ZVXlJ2drYMHD55e9QAAIO4N67tp7rvvPt13330D/uyll17q12eMGc7LAACAcYDvpgEAAFYRRgAAgFWEEQAAYBVhBAAAWEUYAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWDesOrAAAYOwb6nfm2P6+HE5GAACAVYQRAABgFWEEAABYxTUjGJfi5XNUABgPOBkBAABWcTICABgQJ4gYLYQRAEBcISQlHj6mAQAAVhFGAACAVYQRAABgFWEEAABYRRgBAABWEUYAAIBVhBEAAGAVYQQAAFjFTc8AACNiqDcjk7ghGaIRRgAAsIA7yf4vPqYBAABWEUYAAIBVhBEAAGAV14wAAKzhuglInIwAAADLOBnBmMP/KQHA+MLJCAAAsGpYJyMNDQ365S9/qUAgoDlz5qi+vl5FRUWDjt+6dasqKyu1Z88eZWZm6qc//anKy8uHXbRtY/X/3MdqXQBGHv++I5HEHEaamppUUVGhhoYGzZ8/X6tWrVJxcbH27t2rGTNm9Bt/4MAB3XDDDbrnnnv08ssva8eOHbrvvvs0depU/ehHPxqRRQAYOn6JARhrYg4jdXV1Ki0tVVlZmSSpvr5e77zzjhobG1VbW9tv/PPPP68ZM2aovr5ekpSbm6udO3fqmWeeIYwAgAiIYxF7MrpiCiO9vb1qa2vTsmXLovq9Xq9aW1sHnPPnP/9ZXq83qu/73/++1qxZo//85z8666yz+s0Jh8MKh8ORx8FgUJIUCoViKfeMORr+ckjjRrveRKlrOOsYjdfIW/7OkOb8v198f1TrGo3XGM9i3fehjv+/c0Zj34fjTL23hjNntN/zY3XtsbL97/vx5zXGnHygicGhQ4eMJLNjx46o/qeeesrMmjVrwDkXXXSReeqpp6L6duzYYSSZTz/9dMA5y5cvN5JoNBqNRqMlQOvo6DhpvhjWBawOhyPqsTGmX9+pxg/Uf1xVVZUqKysjj48eParPP/9cU6ZMOenrjIRQKKSsrCx1dHQoNTX1jL7WWMPaWTtrHz9YO2sfjbUbY3T48GFlZmaedFxMYSQtLU1JSUnq7OyM6u/q6pLb7R5wTnp6+oDjJ06cqClTpgw4x+l0yul0RvWde+65sZR62lJTU8fdm/Q41s7axxvWztrHm9Fcu8vlOuWYmO4zkpycLI/HI5/PF9Xv8/lUWFg44JyCgoJ+4999913l5+cPeL0IAAAYX2K+6VllZaVeeOEFrV27Vvv27dPDDz8sv98fuW9IVVWVlixZEhlfXl6ujz/+WJWVldq3b5/Wrl2rNWvW6NFHHx25VQAAgLgV8zUjJSUl6unpUU1NjQKBgPLy8tTc3Kzs7GxJUiAQkN/vj4zPyclRc3OzHn74YT333HPKzMzUb37zmzH7Z71Op1PLly/v9zHReMDaWft4w9pZ+3gzVtfuMOZUf28DAABw5vDdNAAAwCrCCAAAsIowAgAArCKMAAAAqwgjJ2hoaFBOTo5SUlLk8XjU0tJiu6Qz7oknnpDD4Yhq6enptss6I7Zt26abbrpJmZmZcjgc+uMf/xj1c2OMnnjiCWVmZmrSpEn67ne/qz179tgpdoSdau133nlnv/fBVVddZafYEVRbW6tvf/vbOuecczRt2jQtXLhQH374YdSYRN33oaw9Ufe9sbFRl112WeTmXgUFBXrrrbciP0/UPZdOvfaxuOeEkf+jqalJFRUVqq6uVnt7u4qKilRcXBz1p8qJas6cOQoEApG2e/du2yWdEUeOHNHcuXP17LPPDvjzp59+WnV1dXr22Wf1/vvvKz09Xddff70OHz48ypWOvFOtXZJ+8IMfRL0PmpubR7HCM2Pr1q26//779d5778nn8+nrr7+W1+vVkSNHImMSdd+HsnYpMfd9+vTpWrFihXbu3KmdO3dqwYIFuvnmmyOBI1H3XDr12qUxuOdD+H68cePKK6805eXlUX0XX3yxWbZsmaWKRsfy5cvN3LlzbZcx6iSZN954I/L46NGjJj093axYsSLS99VXXxmXy2Wef/55CxWeOSeu3Rhjli5dam6++WYr9Yymrq4uI8ls3brVGDO+9v3EtRszfvbdGGO++c1vmhdeeGFc7flxx9duzNjcc05G/qu3t1dtbW3yer1R/V6vV62trZaqGj0fffSRMjMzlZOTo9tvv1379++3XdKoO3DggDo7O6PeA06nU9/5znfGxXtAkrZs2aJp06Zp1qxZuueee9TV1WW7pBEXDAYlSeedd56k8bXvJ679uETf976+Pr322ms6cuSICgoKxtWen7j248bang/rW3sTUXd3t/r6+vp94Z/b7e73RX+JZt68eVq3bp1mzZqlzz77TE8++aQKCwu1Z8+eQb/MMBEd3+eB3gMff/yxjZJGVXFxsW699VZlZ2frwIED+vnPf64FCxaora1tzN2tcbiMMaqsrNTVV1+tvLw8SeNn3wdau5TY+757924VFBToq6++0tlnn6033nhDl1xySSRwJPKeD7Z2aWzuOWHkBA6HI+qxMaZfX6IpLi6O/POll16qgoICXXDBBfrd736nyspKi5XZMR7fA9Kxr3o4Li8vT/n5+crOztamTZt0yy23WKxs5DzwwAP64IMPtH379n4/S/R9H2ztibzvs2fP1q5du/Svf/1LGzZs0NKlS7V169bIzxN5zwdb+yWXXDIm95yPaf4rLS1NSUlJ/U5Burq6+qXnRDd58mRdeuml+uijj2yXMqqO/wUR74FjMjIylJ2dnTDvgwcffFBvvvmmNm/erOnTp0f6x8O+D7b2gSTSvicnJ+vCCy9Ufn6+amtrNXfuXK1cuXJc7Plgax/IWNhzwsh/JScny+PxyOfzRfX7fD4VFhZaqsqOcDisffv2KSMjw3YpoyonJ0fp6elR74He3l5t3bp13L0HJKmnp0cdHR1x/z4wxuiBBx7Qxo0b9ac//Uk5OTlRP0/kfT/V2geSKPs+EGOMwuFwQu/5YI6vfSBjYs9tXTk7Fr322mvmrLPOMmvWrDF79+41FRUVZvLkyebgwYO2SzujHnnkEbNlyxazf/9+895775kf/vCH5pxzzknIdR8+fNi0t7eb9vZ2I8nU1dWZ9vZ28/HHHxtjjFmxYoVxuVxm48aNZvfu3eaOO+4wGRkZJhQKWa789J1s7YcPHzaPPPKIaW1tNQcOHDCbN282BQUF5vzzz4/7tf/kJz8xLpfLbNmyxQQCgUj78ssvI2MSdd9PtfZE3veqqiqzbds2c+DAAfPBBx+Yn/3sZ2bChAnm3XffNcYk7p4bc/K1j9U9J4yc4LnnnjPZ2dkmOTnZXHHFFVF/ApeoSkpKTEZGhjnrrLNMZmamueWWW8yePXtsl3VGbN682Ujq15YuXWqMOfZnnsuXLzfp6enG6XSaa665xuzevdtu0SPkZGv/8ssvjdfrNVOnTjVnnXWWmTFjhlm6dKnx+/22yz5tA61ZknnxxRcjYxJ130+19kTe97vvvjvy3/KpU6eaa6+9NhJEjEncPTfm5Gsfq3vuMMaY0TuHAQAAiMY1IwAAwCrCCAAAsIowAgAArCKMAAAAqwgjAADAKsIIAACwijACAACsIowAAACrCCMAAMAqwggAALCKMAIAAKwijAAAAKv+PwZKgTcdDPN/AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    " # configure to select all features\n",
    " fs = SelectKBest(score_func=mutual_info_regression, k=26)\n",
    " # learn relationship from training data\n",
    " fs.fit(X_train, y_train)\n",
    " # transform train input data\n",
    " X_train_fs = fs.transform(X_train)\n",
    " # transform test input data\n",
    " X_test_fs = fs.transform(X_test)\n",
    " return X_train_fs, X_test_fs, fs\n",
    " \n",
    "# load the dataset\n",
    "# split into train and test sets\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)\n",
    "# what are scores for the features\n",
    "ignr_cnt = 0\n",
    "for i in range(len(fs.scores_)):\n",
    " if (fs.scores_[i] < 0.0015):\n",
    "  ignr_cnt +=1\n",
    " print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "print(ignr_cnt)\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs = np.array(X_train_fs) \n",
    "X_test_fs = np.array(X_test_fs) \n",
    "\n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs = torch.from_numpy(X_train_fs.astype(np.float32))\n",
    "X_test_fs = torch.from_numpy(X_test_fs.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X_train_fs.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(n_features , 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10000\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss()  ####################################################################\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "lambda_reg = 0.01\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_pred = model(X_train_fs)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # Compute L2 regularization term\n",
    "    l2_reg = torch.tensor(0.)\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param)\n",
    "    \n",
    "    # Add regularization term to loss\n",
    "    loss += lambda_reg * l2_reg\n",
    "\n",
    "    # Backward pass and update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero grad before new step\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 2\u001b[0m     y_predicted \u001b[38;5;241m=\u001b[39m model(X_test)\n\u001b[1;32m      3\u001b[0m     y_predicted_cls \u001b[38;5;241m=\u001b[39m y_predicted\u001b[38;5;241m.\u001b[39mround()\n\u001b[1;32m      6\u001b[0m     criterion_last \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[21], line 10\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 10\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1(x)\n\u001b[1;32m     11\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     12\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(out)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mTypeError\u001b[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted = np.array(y_predicted)\n",
    "    y_predicted = torch.from_numpy(y_predicted.astype(np.float32))\n",
    "     \n",
    "    criterion_last = nn.MSELoss()\n",
    "    loss_last = criterion_last(y_predicted, y_test)\n",
    "    print(f'loss: {loss_last:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
