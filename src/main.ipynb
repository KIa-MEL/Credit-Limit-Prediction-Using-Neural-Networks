{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiplicativeLR\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The dataset is shown below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>51.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>40.0</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10128</th>\n",
       "      <td>712110333</td>\n",
       "      <td>37.0</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>2568</td>\n",
       "      <td>48</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10134</th>\n",
       "      <td>712674183</td>\n",
       "      <td>53.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4065.0</td>\n",
       "      <td>2180</td>\n",
       "      <td>0.321</td>\n",
       "      <td>1271</td>\n",
       "      <td>36</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10135</th>\n",
       "      <td>718421808</td>\n",
       "      <td>56.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3068.0</td>\n",
       "      <td>1765</td>\n",
       "      <td>0.853</td>\n",
       "      <td>4611</td>\n",
       "      <td>73</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.575</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10136</th>\n",
       "      <td>809452383</td>\n",
       "      <td>37.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>4733</td>\n",
       "      <td>89</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>788786208</td>\n",
       "      <td>46.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>College</td>\n",
       "      <td>Married</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9881.0</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.582</td>\n",
       "      <td>4725</td>\n",
       "      <td>85</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.182</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10132 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLIENTNUM  Customer_Age Gender  Dependent_count Education_Level  \\\n",
       "0      768805383          45.0      M                3     High School   \n",
       "1      818770008          49.0      F                5        Graduate   \n",
       "2      713982108          51.0      M                3        Graduate   \n",
       "3      769911858          40.0      F                4     High School   \n",
       "4      709106358          40.0      M                3      Uneducated   \n",
       "...          ...           ...    ...              ...             ...   \n",
       "10128  712110333          37.0      F                3     High School   \n",
       "10134  712674183          53.0      M                2         College   \n",
       "10135  718421808          56.0      F                2      Uneducated   \n",
       "10136  809452383          37.0      F                2        Graduate   \n",
       "10145  788786208          46.0      F                2         College   \n",
       "\n",
       "      Marital_Status Income_Category Card_Category  Months_on_book  \\\n",
       "0            Married     $60K - $80K          Blue            39.0   \n",
       "1                NaN  Less than $40K          Blue            44.0   \n",
       "2            Married    $80K - $120K          Blue            36.0   \n",
       "3                NaN  Less than $40K          Blue            34.0   \n",
       "4            Married     $60K - $80K           NaN            21.0   \n",
       "...              ...             ...           ...             ...   \n",
       "10128            NaN         Unknown           NaN            18.0   \n",
       "10134            NaN     $40K - $60K          Blue            33.0   \n",
       "10135        Married         Unknown          Blue            43.0   \n",
       "10136        Married  Less than $40K           NaN            32.0   \n",
       "10145        Married         Unknown          Blue            27.0   \n",
       "\n",
       "       Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0                           5.0                       1   \n",
       "1                           6.0                       1   \n",
       "2                           4.0                       1   \n",
       "3                           3.0                       4   \n",
       "4                           5.0                       1   \n",
       "...                         ...                     ...   \n",
       "10128                       4.0                       1   \n",
       "10134                       3.0                       3   \n",
       "10135                       6.0                       3   \n",
       "10136                       6.0                       1   \n",
       "10145                       6.0                       3   \n",
       "\n",
       "       Contacts_Count_12_mon  Credit_Limit  Total_Revolving_Bal  \\\n",
       "0                          3       12691.0                  777   \n",
       "1                          2        8256.0                  864   \n",
       "2                          0        3418.0                    0   \n",
       "3                          1        3313.0                 2517   \n",
       "4                          0        4716.0                    0   \n",
       "...                      ...           ...                  ...   \n",
       "10128                      3        2179.0                    0   \n",
       "10134                      1        4065.0                 2180   \n",
       "10135                      2        3068.0                 1765   \n",
       "10136                      3        1438.3                    0   \n",
       "10145                      3        9881.0                 1794   \n",
       "\n",
       "       Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "0                     1.335             1144              42   \n",
       "1                     1.541             1291              33   \n",
       "2                     2.594             1887              20   \n",
       "3                     1.405             1171              20   \n",
       "4                     2.175              816              28   \n",
       "...                     ...              ...             ...   \n",
       "10128                 0.725             2568              48   \n",
       "10134                 0.321             1271              36   \n",
       "10135                 0.853             4611              73   \n",
       "10136                 0.707             4733              89   \n",
       "10145                 0.582             4725              85   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Unnamed: 19  \n",
       "0                    1.625                  0.061          NaN  \n",
       "1                    3.714                  0.105          NaN  \n",
       "2                    2.333                  0.000          NaN  \n",
       "3                    2.333                  0.760          NaN  \n",
       "4                    2.500                  0.000          NaN  \n",
       "...                    ...                    ...          ...  \n",
       "10128                0.297                  0.000          NaN  \n",
       "10134                0.200                  0.536          NaN  \n",
       "10135                0.698                  0.575          NaN  \n",
       "10136                0.816                  0.000          NaN  \n",
       "10145                0.735                  0.182          NaN  \n",
       "\n",
       "[10132 rows x 20 columns]"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('../data/CreditPrediction.csv')\n",
    "# removing duplicated datas\n",
    "data_no_dup = data_df.drop_duplicates() \n",
    "# data_no_dup = data_no_dup.fillna(0)\n",
    "# data_no_dup = pd.get_dummies(data_no_dup, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True, )\n",
    "\n",
    "data_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_values(df):\n",
    "    # Identify numerical and categorical columns\n",
    "    num_cols = df.select_dtypes(exclude='object').columns\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "    # Create transformers for numerical and categorical data\n",
    "    num_transformer = IterativeImputer()\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Combine transformers into a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols),\n",
    "            ('cat', cat_transformer, cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply the transformations\n",
    "    preprocessed_data = preprocessor.fit_transform(data_no_dup)\n",
    "\n",
    "    # Convert the result back to a DataFrame (optional)\n",
    "    preprocessed_df = pd.DataFrame(preprocessed_data)\n",
    "\n",
    "    # Display the preprocessed DataFrame\n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kianoosh/anaconda3/envs/pytorch/lib/python3.11/site-packages/sklearn/impute/_base.py:597: UserWarning: Skipping features without any observed values: [13]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = data_no_dup.drop('Credit_Limit', axis=1)\n",
    "y = data_no_dup['Credit_Limit']\n",
    "\n",
    "X = fix_missing_values(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6788, 26)"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=53)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(.95)\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    " # configure to select all features\n",
    " fs = SelectKBest(score_func=mutual_info_regression, k=25)\n",
    " # learn relationship from training data\n",
    " fs.fit(X_train, y_train)\n",
    " # transform train input data\n",
    " X_train_fs = fs.transform(X_train)\n",
    " # transform test input data\n",
    " X_test_fs = fs.transform(X_test)\n",
    " return X_train_fs, X_test_fs, fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.464103\n",
      "Feature 1: 0.096913\n",
      "Feature 2: 0.048729\n",
      "Feature 3: 0.098541\n",
      "Feature 4: 0.019367\n",
      "Feature 5: 0.049809\n",
      "Feature 6: 0.023766\n",
      "Feature 7: 0.008655\n",
      "Feature 8: 0.093304\n",
      "Feature 9: 0.049339\n",
      "Feature 10: 0.041244\n",
      "Feature 11: 0.065974\n",
      "Feature 12: 0.042723\n",
      "Feature 13: 0.034182\n",
      "Feature 14: 0.053400\n",
      "Feature 15: 0.075572\n",
      "Feature 16: 0.028420\n",
      "Feature 17: 0.074381\n",
      "Feature 18: 0.075672\n",
      "Feature 19: 0.028535\n",
      "Feature 20: 0.009424\n",
      "Feature 21: 0.038563\n",
      "Feature 22: 0.017363\n",
      "Feature 23: 0.005919\n",
      "Feature 24: 0.009709\n",
      "Feature 25: 0.000000\n",
      "1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAal0lEQVR4nO3dfWxV9f3A8Q9FW0RoATtawUoFnMwpZVLbscWHxc6ixI3pEnRmsIawbIJRG53iJtW5pfgwwyZEMzO3xA1lJuqyh7CZTlyMVTYYcW5KlEhAsQVcbLXMYuj5/WGsvwoIFyhfbnm9kpPA4Zx7P/d4DG/OPfd2UJZlWQAAJFKQegAA4OgmRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAIKljUg+wP3p6emLLli0xfPjwGDRoUOpxAID9kGVZvPPOOzFmzJgoKNj79Y+8iJEtW7ZERUVF6jEAgAOwefPmOOmkk/b653kRI8OHD4+ID15McXFx4mkAgP3R2dkZFRUVvX+P701exMiHb80UFxeLEQDIM/u6xcINrABAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApI5JPUBqlTf98YD227h4xiGeBACOTq6MAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApA4oRpYtWxaVlZUxZMiQqK2tjdWrV+/Xfo888kgMGjQoZs6ceSBPCwAMQDnHyIoVK6KxsTGamppi7dq1UVVVFfX19bF169ZP3G/jxo1x/fXXxznnnHPAwwIAA0/OMXLPPffEvHnzoqGhIU4//fS4//77Y+jQofHggw/udZ9du3bFlVdeGbfddluMHz/+oAYGAAaWnGJk586dsWbNmqirq/voAQoKoq6uLlpbW/e63w9/+MMYPXp0zJ07d7+ep7u7Ozo7O/ssAMDAlFOMbN++PXbt2hVlZWV91peVlUVbW9se93nmmWfiF7/4RTzwwAP7/TzNzc1RUlLSu1RUVOQyJgCQR/r10zTvvPNOfPOb34wHHnggSktL93u/hQsXRkdHR++yefPmfpwSAEjpmFw2Li0tjcGDB0d7e3uf9e3t7VFeXr7b9hs2bIiNGzfGJZdc0ruup6fngyc+5phYv359TJgwYbf9ioqKoqioKJfRAIA8ldOVkcLCwpg6dWq0tLT0ruvp6YmWlpaYNm3abttPmjQp/vWvf8W6det6l6985SvxpS99KdatW+ftFwAgtysjERGNjY0xZ86cqK6ujpqamliyZEl0dXVFQ0NDRETMnj07xo4dG83NzTFkyJA444wz+uw/YsSIiIjd1gMAR6ecY2TWrFmxbdu2WLRoUbS1tcWUKVNi5cqVvTe1btq0KQoKfLErALB/BmVZlqUeYl86OzujpKQkOjo6ori4+JA+duVNfzyg/TYunnFI5wCAgWZ///52CQMASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABI6oBiZNmyZVFZWRlDhgyJ2traWL169V63feyxx6K6ujpGjBgRxx9/fEyZMiUeeuihAx4YABhYco6RFStWRGNjYzQ1NcXatWujqqoq6uvrY+vWrXvcftSoUfH9738/Wltb44UXXoiGhoZoaGiIP//5zwc9PACQ/wZlWZblskNtbW2cffbZsXTp0oiI6OnpiYqKirj66qvjpptu2q/HOOuss2LGjBlx++2379f2nZ2dUVJSEh0dHVFcXJzLuPtUedMfD2i/jYtnHNI5AGCg2d+/v3O6MrJz585Ys2ZN1NXVffQABQVRV1cXra2t+9w/y7JoaWmJ9evXx7nnnrvX7bq7u6Ozs7PPAgAMTDnFyPbt22PXrl1RVlbWZ31ZWVm0tbXtdb+Ojo4YNmxYFBYWxowZM+Lee++NL3/5y3vdvrm5OUpKSnqXioqKXMYEAPLIYfk0zfDhw2PdunXx97//PX784x9HY2NjrFq1aq/bL1y4MDo6OnqXzZs3H44xAYAEjsll49LS0hg8eHC0t7f3Wd/e3h7l5eV73a+goCAmTpwYERFTpkyJl156KZqbm+P888/f4/ZFRUVRVFSUy2gAQJ7K6cpIYWFhTJ06NVpaWnrX9fT0REtLS0ybNm2/H6enpye6u7tzeWoAYIDK6cpIRERjY2PMmTMnqquro6amJpYsWRJdXV3R0NAQERGzZ8+OsWPHRnNzc0R8cP9HdXV1TJgwIbq7u+NPf/pTPPTQQ3Hfffcd2lcCAOSlnGNk1qxZsW3btli0aFG0tbXFlClTYuXKlb03tW7atCkKCj664NLV1RVXXXVVvP7663HcccfFpEmT4te//nXMmjXr0L0KACBv5fw9Iyn4nhEAyD/98j0jAACHmhgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApA4oRpYtWxaVlZUxZMiQqK2tjdWrV+912wceeCDOOeecGDlyZIwcOTLq6uo+cXsA4OiSc4ysWLEiGhsbo6mpKdauXRtVVVVRX18fW7du3eP2q1atiiuuuCKeeuqpaG1tjYqKirjwwgvjjTfeOOjhAYD8NyjLsiyXHWpra+Pss8+OpUuXRkRET09PVFRUxNVXXx033XTTPvfftWtXjBw5MpYuXRqzZ8/er+fs7OyMkpKS6OjoiOLi4lzG3afKm/54QPttXDzjkM4BAAPN/v79ndOVkZ07d8aaNWuirq7uowcoKIi6urpobW3dr8fYsWNHvP/++zFq1KhcnhoAGKCOyWXj7du3x65du6KsrKzP+rKysnj55Zf36zFuvPHGGDNmTJ+g+bju7u7o7u7u/X1nZ2cuYwIAeeSwfppm8eLF8cgjj8Tjjz8eQ4YM2et2zc3NUVJS0rtUVFQcxikBgMMppxgpLS2NwYMHR3t7e5/17e3tUV5e/on73n333bF48eL4y1/+EpMnT/7EbRcuXBgdHR29y+bNm3MZEwDIIznFSGFhYUydOjVaWlp61/X09ERLS0tMmzZtr/vdeeedcfvtt8fKlSujurp6n89TVFQUxcXFfRYAYGDK6Z6RiIjGxsaYM2dOVFdXR01NTSxZsiS6urqioaEhIiJmz54dY8eOjebm5oiIuOOOO2LRokWxfPnyqKysjLa2toiIGDZsWAwbNuwQvhQAIB/lHCOzZs2Kbdu2xaJFi6KtrS2mTJkSK1eu7L2pddOmTVFQ8NEFl/vuuy927twZX//61/s8TlNTU9x6660HNz0AkPdy/p6RFHzPCADkn375nhEAgENNjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJISIwBAUmIEAEhKjAAASYkRACApMQIAJCVGAICkxAgAkJQYAQCSEiMAQFJiBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASOqAYmTZsmVRWVkZQ4YMidra2li9evVet/33v/8dl112WVRWVsagQYNiyZIlBzorADAA5RwjK1asiMbGxmhqaoq1a9dGVVVV1NfXx9atW/e4/Y4dO2L8+PGxePHiKC8vP+iBAYCBJecYueeee2LevHnR0NAQp59+etx///0xdOjQePDBB/e4/dlnnx133XVXXH755VFUVHTQAwMAA0tOMbJz585Ys2ZN1NXVffQABQVRV1cXra2th2yo7u7u6Ozs7LMAAANTTjGyffv22LVrV5SVlfVZX1ZWFm1tbYdsqObm5igpKeldKioqDtljAwBHliPy0zQLFy6Mjo6O3mXz5s2pRwIA+skxuWxcWloagwcPjvb29j7r29vbD+nNqUVFRe4vOQiVN/3xgPbbuHjGIZ4EAPYtpxgpLCyMqVOnRktLS8ycOTMiInp6eqKlpSUWLFjQH/PlDQEAAAcmpxiJiGhsbIw5c+ZEdXV11NTUxJIlS6KrqysaGhoiImL27NkxduzYaG5ujogPbnr9z3/+0/vrN954I9atWxfDhg2LiRMnHsKXAgDko5xjZNasWbFt27ZYtGhRtLW1xZQpU2LlypW9N7Vu2rQpCgo+uhVly5Yt8bnPfa7393fffXfcfffdcd5558WqVasO/hUAAHkt5xiJiFiwYMFe35b5eGBUVlZGlmUH8jRwxPF2HMChd0R+mgYAOHqIEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKQO6AflAQxkA/EHIg7E18TAIUYAjmAigqOBt2kAgKTECACQlBgBAJISIwBAUmIEAEjKp2ngKHcgn9bwSQ3gUHJlBABISowAAEmJEQAgKTECACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASMo3sAIDyoF8o2yEb5WFlFwZAQCScmWEfuVfqQDsixg5gviL++jhvzXAR7xNAwAkJUYAgKTECACQlBgBAJJyAytw0NyQCxwMMQJ5SgAAA4W3aQCApFwZASDvuDI4sLgyAgAkJUYAgKS8TQMcEVx2h6OXKyMAQFJiBABISowAAEmJEQAgKTewAvSTgXZT7kB7PRw5XBkBAJISIwBAUt6m4Yjn0jDAwObKCACQlBgBAJISIwBAUu4ZYY/cpwHA4SJGADhq+YfXkcHbNABAUmIEAEhKjAAASYkRACApMQIAJOXTNAAcVj7BsmdH83ERIxw1jub/0QGOZN6mAQCSOqArI8uWLYu77ror2traoqqqKu69996oqanZ6/aPPvpo3HLLLbFx48Y49dRT44477oiLL774gIcGgCOFq64HL+crIytWrIjGxsZoamqKtWvXRlVVVdTX18fWrVv3uP2zzz4bV1xxRcydOzf++c9/xsyZM2PmzJnx4osvHvTwAED+yzlG7rnnnpg3b140NDTE6aefHvfff38MHTo0HnzwwT1u/9Of/jSmT58eN9xwQ3zmM5+J22+/Pc4666xYunTpQQ8PAOS/nN6m2blzZ6xZsyYWLlzYu66goCDq6uqitbV1j/u0trZGY2Njn3X19fXxxBNP7PV5uru7o7u7u/f3HR0dERHR2dmZy7j7pad7xwHt9/FZDsXjmMUs+TLLQHs9ZjHLQJnlSPPhbFmWffKGWQ7eeOONLCKyZ599ts/6G264IaupqdnjPscee2y2fPnyPuuWLVuWjR49eq/P09TUlEWExWKxWCyWAbBs3rz5E/viiPxo78KFC/tcTenp6Yn//ve/ccIJJ8SgQYMOywydnZ1RUVERmzdvjuLi4sPynEcTx7f/OLb9x7HtX45v/0l1bLMsi3feeSfGjBnzidvlFCOlpaUxePDgaG9v77O+vb09ysvL97hPeXl5TttHRBQVFUVRUVGfdSNGjMhl1EOmuLjY/xT9yPHtP45t/3Fs+5fj239SHNuSkpJ9bpPTDayFhYUxderUaGlp6V3X09MTLS0tMW3atD3uM23atD7bR0Q8+eSTe90eADi65Pw2TWNjY8yZMyeqq6ujpqYmlixZEl1dXdHQ0BAREbNnz46xY8dGc3NzRERcc801cd5558VPfvKTmDFjRjzyyCPxj3/8I37+858f2lcCAOSlnGNk1qxZsW3btli0aFG0tbXFlClTYuXKlVFWVhYREZs2bYqCgo8uuHzhC1+I5cuXxw9+8IO4+eab49RTT40nnngizjjjjEP3KvpBUVFRNDU17fZ2EYeG49t/HNv+49j2L8e3/xzpx3ZQlu3r8zYAAP3Hz6YBAJISIwBAUmIEAEhKjAAASYmRvVi2bFlUVlbGkCFDora2NlavXp16pLx36623xqBBg/oskyZNSj1W3vrb3/4Wl1xySYwZMyYGDRq02897yrIsFi1aFCeeeGIcd9xxUVdXF6+88kqaYfPMvo7tt771rd3O5enTp6cZNs80NzfH2WefHcOHD4/Ro0fHzJkzY/369X22ee+992L+/PlxwgknxLBhw+Kyyy7b7csz2d3+HNvzzz9/t3P3O9/5TqKJPyJG9mDFihXR2NgYTU1NsXbt2qiqqor6+vrYunVr6tHy3mc/+9l48803e5dnnnkm9Uh5q6urK6qqqmLZsmV7/PM777wzfvazn8X9998fzz//fBx//PFRX18f77333mGeNP/s69hGREyfPr3Pufzwww8fxgnz19NPPx3z58+P5557Lp588sl4//3348ILL4yurq7eba677rr4/e9/H48++mg8/fTTsWXLlrj00ksTTp0f9ufYRkTMmzevz7l75513Jpr4/9mPn4931Kmpqcnmz5/f+/tdu3ZlY8aMyZqbmxNOlf+ampqyqqqq1GMMSBGRPf74472/7+npycrLy7O77rqrd93bb7+dFRUVZQ8//HCCCfPXx49tlmXZnDlzsq9+9atJ5hlotm7dmkVE9vTTT2dZ9sF5euyxx2aPPvpo7zYvvfRSFhFZa2trqjHz0sePbZZl2XnnnZddc8016YbaC1dGPmbnzp2xZs2aqKur611XUFAQdXV10dramnCygeGVV16JMWPGxPjx4+PKK6+MTZs2pR5pQHrttdeira2tz3lcUlIStbW1zuNDZNWqVTF69Og47bTT4rvf/W689dZbqUfKSx0dHRERMWrUqIiIWLNmTbz//vt9zt1JkybFySef7NzN0ceP7Yd+85vfRGlpaZxxxhmxcOHC2LFjR4rx+jgif2pvStu3b49du3b1fqPsh8rKyuLll19ONNXAUFtbG7/61a/itNNOizfffDNuu+22OOecc+LFF1+M4cOHpx5vQGlra4uI2ON5/OGfceCmT58el156aZxyyimxYcOGuPnmm+Oiiy6K1tbWGDx4cOrx8kZPT09ce+218cUvfrH3W7nb2tqisLBwtx+O6tzNzZ6ObUTEN77xjRg3blyMGTMmXnjhhbjxxhtj/fr18dhjjyWcVoxwGF100UW9v548eXLU1tbGuHHj4re//W3MnTs34WSQm8svv7z312eeeWZMnjw5JkyYEKtWrYoLLrgg4WT5Zf78+fHiiy+6d6wf7O3Yfvvb3+799ZlnnhknnnhiXHDBBbFhw4aYMGHC4R6zl7dpPqa0tDQGDx68253b7e3tUV5enmiqgWnEiBHx6U9/Ol599dXUoww4H56rzuPDY/z48VFaWupczsGCBQviD3/4Qzz11FNx0kkn9a4vLy+PnTt3xttvv91ne+fu/tvbsd2T2traiIjk564Y+ZjCwsKYOnVqtLS09K7r6emJlpaWmDZtWsLJBp533303NmzYECeeeGLqUQacU045JcrLy/ucx52dnfH88887j/vB66+/Hm+99ZZzeT9kWRYLFiyIxx9/PP7617/GKaec0ufPp06dGscee2yfc3f9+vWxadMm5+4+7OvY7sm6desiIpKfu96m2YPGxsaYM2dOVFdXR01NTSxZsiS6urqioaEh9Wh57frrr49LLrkkxo0bF1u2bImmpqYYPHhwXHHFFalHy0vvvvtun3/NvPbaa7Fu3boYNWpUnHzyyXHttdfGj370ozj11FPjlFNOiVtuuSXGjBkTM2fOTDd0nvikYztq1Ki47bbb4rLLLovy8vLYsGFDfO9734uJEydGfX19wqnzw/z582P58uXxu9/9LoYPH957H0hJSUkcd9xxUVJSEnPnzo3GxsYYNWpUFBcXx9VXXx3Tpk2Lz3/+84mnP7Lt69hu2LAhli9fHhdffHGccMIJ8cILL8R1110X5557bkyePDnt8Kk/znOkuvfee7OTTz45KywszGpqarLnnnsu9Uh5b9asWdmJJ56YFRYWZmPHjs1mzZqVvfrqq6nHyltPPfVUFhG7LXPmzMmy7IOP995yyy1ZWVlZVlRUlF1wwQXZ+vXr0w6dJz7p2O7YsSO78MILs0996lPZsccem40bNy6bN29e1tbWlnrsvLCn4xoR2S9/+cvebf73v/9lV111VTZy5Mhs6NCh2de+9rXszTffTDd0ntjXsd20aVN27rnnZqNGjcqKioqyiRMnZjfccEPW0dGRdvAsywZlWZYdzvgBAPj/3DMCACQlRgCApMQIAJCUGAEAkhIjAEBSYgQASEqMAABJiREAICkxAgAkJUYAgKTECACQlBgBAJL6P7PzyTUZVgBUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# what are scores for the features\n",
    "ignr_cnt = 0\n",
    "for i in range(len(fs.scores_)):\n",
    " if (fs.scores_[i] < 0.0015):\n",
    "  ignr_cnt +=1\n",
    " print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "print(ignr_cnt)\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs = np.array(X_train_fs) \n",
    "X_test_fs = np.array(X_test_fs) \n",
    "\n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs = torch.from_numpy(X_train_fs.astype(np.float32))\n",
    "X_test_fs = torch.from_numpy(X_test_fs.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "_, n_features = X_train_fs.shape\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs  = X_train_fs.to(device)\n",
    "y_train = y_train.to(device)\n",
    "\n",
    "X_test_fs  = X_test_fs.to(device)\n",
    "y_test = y_test.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.leaky_reLu = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        out = self.linear1(x)\n",
    "        out = self.leaky_reLu(out)\n",
    "        out = self.linear2(out)\n",
    "        # out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Model2, self).__init__()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.leaky_reLu = nn.LeakyReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "        self.linear2 = nn.Linear(hidden_size, int(hidden_size/2))\n",
    "        self.linear3 = nn.Linear(int(hidden_size/2), int(hidden_size/4))\n",
    "        self.linear4 = nn.Linear(int(hidden_size/4), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.dropout(x)\n",
    "        out = self.linear1(out)\n",
    "        out = self.leaky_reLu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.leaky_reLu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.leaky_reLu(out)\n",
    "        out = self.linear4(out)\n",
    "        # out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model2(n_features , 50)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.linear_model import LinearRegression \n",
    "# regr = LinearRegression() \n",
    "  \n",
    "# regr.fit(X_train_fs, y_train) \n",
    "# # print(regr.score(X_test_fs, y_test)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = regr.predict(X_test_fs)\n",
    "# MSE = mean_squared_error(y_pred, y_test)\n",
    "# MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1000, loss = 41652956.0000 || lr: 0.0010000\n",
      "epoch: 2000, loss = 40481768.0000 || lr: 0.0010000\n",
      "epoch: 3000, loss = 40362356.0000 || lr: 0.0010000\n",
      "epoch: 4000, loss = 38675388.0000 || lr: 0.0010000\n",
      "epoch: 5000, loss = 38413908.0000 || lr: 0.0010000\n",
      "epoch: 6000, loss = 37759144.0000 || lr: 0.0009500\n",
      "epoch: 7000, loss = 38444020.0000 || lr: 0.0009500\n",
      "epoch: 8000, loss = 37617516.0000 || lr: 0.0009500\n",
      "epoch: 9000, loss = 38390156.0000 || lr: 0.0009500\n",
      "epoch: 10000, loss = 37809928.0000 || lr: 0.0009500\n",
      "epoch: 11000, loss = 36635772.0000 || lr: 0.0009025\n",
      "epoch: 12000, loss = 36037192.0000 || lr: 0.0009025\n",
      "epoch: 13000, loss = 34252920.0000 || lr: 0.0009025\n",
      "epoch: 14000, loss = 32292670.0000 || lr: 0.0009025\n",
      "epoch: 15000, loss = 32132932.0000 || lr: 0.0009025\n",
      "epoch: 16000, loss = 31470406.0000 || lr: 0.0008574\n",
      "epoch: 17000, loss = 30597188.0000 || lr: 0.0008574\n",
      "epoch: 18000, loss = 30032976.0000 || lr: 0.0008574\n",
      "epoch: 19000, loss = 29498522.0000 || lr: 0.0008574\n",
      "epoch: 20000, loss = 30152868.0000 || lr: 0.0008574\n",
      "epoch: 21000, loss = 28463514.0000 || lr: 0.0008145\n",
      "epoch: 22000, loss = 29346218.0000 || lr: 0.0008145\n",
      "epoch: 23000, loss = 28211430.0000 || lr: 0.0008145\n",
      "epoch: 24000, loss = 28596492.0000 || lr: 0.0008145\n",
      "epoch: 25000, loss = 26534636.0000 || lr: 0.0008145\n",
      "epoch: 26000, loss = 28072644.0000 || lr: 0.0007738\n",
      "epoch: 27000, loss = 27196308.0000 || lr: 0.0007738\n",
      "epoch: 28000, loss = 27053452.0000 || lr: 0.0007738\n",
      "epoch: 29000, loss = 27379332.0000 || lr: 0.0007738\n",
      "epoch: 30000, loss = 26301830.0000 || lr: 0.0007738\n",
      "epoch: 31000, loss = 26627112.0000 || lr: 0.0007351\n",
      "epoch: 32000, loss = 26358034.0000 || lr: 0.0007351\n",
      "epoch: 33000, loss = 25995930.0000 || lr: 0.0007351\n",
      "epoch: 34000, loss = 25983222.0000 || lr: 0.0007351\n",
      "epoch: 35000, loss = 26491480.0000 || lr: 0.0007351\n",
      "epoch: 36000, loss = 26138826.0000 || lr: 0.0006983\n",
      "epoch: 37000, loss = 26395824.0000 || lr: 0.0006983\n",
      "epoch: 38000, loss = 25862688.0000 || lr: 0.0006983\n",
      "epoch: 39000, loss = 26305490.0000 || lr: 0.0006983\n",
      "epoch: 40000, loss = 26467502.0000 || lr: 0.0006983\n",
      "epoch: 41000, loss = 26240384.0000 || lr: 0.0006634\n",
      "epoch: 42000, loss = 25575336.0000 || lr: 0.0006634\n",
      "epoch: 43000, loss = 26329178.0000 || lr: 0.0006634\n",
      "epoch: 44000, loss = 25826506.0000 || lr: 0.0006634\n",
      "epoch: 45000, loss = 26072204.0000 || lr: 0.0006634\n",
      "epoch: 46000, loss = 25354476.0000 || lr: 0.0006302\n",
      "epoch: 47000, loss = 25642918.0000 || lr: 0.0006302\n",
      "epoch: 48000, loss = 25019904.0000 || lr: 0.0006302\n",
      "epoch: 49000, loss = 25348540.0000 || lr: 0.0006302\n",
      "epoch: 50000, loss = 25461222.0000 || lr: 0.0006302\n",
      "epoch: 51000, loss = 25123030.0000 || lr: 0.0005987\n",
      "epoch: 52000, loss = 24914896.0000 || lr: 0.0005987\n",
      "epoch: 53000, loss = 25190216.0000 || lr: 0.0005987\n",
      "epoch: 54000, loss = 25648214.0000 || lr: 0.0005987\n",
      "epoch: 55000, loss = 24768266.0000 || lr: 0.0005987\n",
      "epoch: 56000, loss = 24815724.0000 || lr: 0.0005688\n",
      "epoch: 57000, loss = 24247720.0000 || lr: 0.0005688\n",
      "epoch: 58000, loss = 24552788.0000 || lr: 0.0005688\n",
      "epoch: 59000, loss = 24367070.0000 || lr: 0.0005688\n",
      "epoch: 60000, loss = 24352400.0000 || lr: 0.0005688\n",
      "epoch: 61000, loss = 23924350.0000 || lr: 0.0005404\n",
      "epoch: 62000, loss = 23538168.0000 || lr: 0.0005404\n",
      "epoch: 63000, loss = 25394208.0000 || lr: 0.0005404\n",
      "epoch: 64000, loss = 24597774.0000 || lr: 0.0005404\n",
      "epoch: 65000, loss = 23412232.0000 || lr: 0.0005404\n",
      "epoch: 66000, loss = 23111300.0000 || lr: 0.0005133\n",
      "epoch: 67000, loss = 23476506.0000 || lr: 0.0005133\n",
      "epoch: 68000, loss = 23509156.0000 || lr: 0.0005133\n",
      "epoch: 69000, loss = 23066200.0000 || lr: 0.0005133\n",
      "epoch: 70000, loss = 23763078.0000 || lr: 0.0005133\n",
      "epoch: 71000, loss = 22905766.0000 || lr: 0.0004877\n",
      "epoch: 72000, loss = 22064268.0000 || lr: 0.0004877\n",
      "epoch: 73000, loss = 22426204.0000 || lr: 0.0004877\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000000\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()  ####################################################################\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "lmbda = lambda epoch: 0.95\n",
    "\n",
    "scheduler = MultiplicativeLR(optimizer, lr_lambda=lmbda)\n",
    "lambda_reg = 0.01\n",
    "loss = 0\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    model.zero_grad()\n",
    "    y_pred = model(X_train_fs)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # TODO Validation\n",
    "    # TODO Bath\n",
    "    # TODO 2 for\n",
    "\n",
    "    # # Compute L2 regularization term\n",
    "    l2_reg = torch.tensor(0.)\n",
    "    l2_reg = l2_reg.to(device)\n",
    "\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param)\n",
    "    \n",
    "    # Add regularization term to loss\n",
    "    loss += lambda_reg * l2_reg\n",
    "\n",
    "    # Backward pass and update\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # zero grad before new step\n",
    "\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f\"epoch: {epoch+1}, loss = {loss.item():.4f} || \"\n",
    "              f\"lr: {optimizer.state_dict()['param_groups'][0]['lr']:.7f}\")\n",
    "    if (epoch+1) % 5000 == 0:\n",
    "        scheduler.step()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66097460.0"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test_fs)\n",
    "    # y_predicted = np.array(y_predicted)\n",
    "     \n",
    "    MSE = mean_squared_error(y_predicted.cpu(), y_test.cpu())\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(38.0383, device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
