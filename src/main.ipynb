{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **The dataset is shown below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLIENTNUM</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Unnamed: 19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>768805383</td>\n",
       "      <td>45.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>39.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12691.0</td>\n",
       "      <td>777</td>\n",
       "      <td>1.335</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>818770008</td>\n",
       "      <td>49.0</td>\n",
       "      <td>F</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8256.0</td>\n",
       "      <td>864</td>\n",
       "      <td>1.541</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713982108</td>\n",
       "      <td>51.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>$80K - $120K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>36.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.594</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>769911858</td>\n",
       "      <td>40.0</td>\n",
       "      <td>F</td>\n",
       "      <td>4</td>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>2517</td>\n",
       "      <td>1.405</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>709106358</td>\n",
       "      <td>40.0</td>\n",
       "      <td>M</td>\n",
       "      <td>3</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>$60K - $80K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4716.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.175</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10128</th>\n",
       "      <td>712110333</td>\n",
       "      <td>37.0</td>\n",
       "      <td>F</td>\n",
       "      <td>3</td>\n",
       "      <td>High School</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2179.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.725</td>\n",
       "      <td>2568</td>\n",
       "      <td>48</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10134</th>\n",
       "      <td>712674183</td>\n",
       "      <td>53.0</td>\n",
       "      <td>M</td>\n",
       "      <td>2</td>\n",
       "      <td>College</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$40K - $60K</td>\n",
       "      <td>Blue</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4065.0</td>\n",
       "      <td>2180</td>\n",
       "      <td>0.321</td>\n",
       "      <td>1271</td>\n",
       "      <td>36</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.536</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10135</th>\n",
       "      <td>718421808</td>\n",
       "      <td>56.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Uneducated</td>\n",
       "      <td>Married</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>43.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3068.0</td>\n",
       "      <td>1765</td>\n",
       "      <td>0.853</td>\n",
       "      <td>4611</td>\n",
       "      <td>73</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.575</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10136</th>\n",
       "      <td>809452383</td>\n",
       "      <td>37.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Married</td>\n",
       "      <td>Less than $40K</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1438.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.707</td>\n",
       "      <td>4733</td>\n",
       "      <td>89</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10145</th>\n",
       "      <td>788786208</td>\n",
       "      <td>46.0</td>\n",
       "      <td>F</td>\n",
       "      <td>2</td>\n",
       "      <td>College</td>\n",
       "      <td>Married</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Blue</td>\n",
       "      <td>27.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9881.0</td>\n",
       "      <td>1794</td>\n",
       "      <td>0.582</td>\n",
       "      <td>4725</td>\n",
       "      <td>85</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.182</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10132 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CLIENTNUM  Customer_Age Gender  Dependent_count Education_Level  \\\n",
       "0      768805383          45.0      M                3     High School   \n",
       "1      818770008          49.0      F                5        Graduate   \n",
       "2      713982108          51.0      M                3        Graduate   \n",
       "3      769911858          40.0      F                4     High School   \n",
       "4      709106358          40.0      M                3      Uneducated   \n",
       "...          ...           ...    ...              ...             ...   \n",
       "10128  712110333          37.0      F                3     High School   \n",
       "10134  712674183          53.0      M                2         College   \n",
       "10135  718421808          56.0      F                2      Uneducated   \n",
       "10136  809452383          37.0      F                2        Graduate   \n",
       "10145  788786208          46.0      F                2         College   \n",
       "\n",
       "      Marital_Status Income_Category Card_Category  Months_on_book  \\\n",
       "0            Married     $60K - $80K          Blue            39.0   \n",
       "1                NaN  Less than $40K          Blue            44.0   \n",
       "2            Married    $80K - $120K          Blue            36.0   \n",
       "3                NaN  Less than $40K          Blue            34.0   \n",
       "4            Married     $60K - $80K           NaN            21.0   \n",
       "...              ...             ...           ...             ...   \n",
       "10128            NaN         Unknown           NaN            18.0   \n",
       "10134            NaN     $40K - $60K          Blue            33.0   \n",
       "10135        Married         Unknown          Blue            43.0   \n",
       "10136        Married  Less than $40K           NaN            32.0   \n",
       "10145        Married         Unknown          Blue            27.0   \n",
       "\n",
       "       Total_Relationship_Count  Months_Inactive_12_mon  \\\n",
       "0                           5.0                       1   \n",
       "1                           6.0                       1   \n",
       "2                           4.0                       1   \n",
       "3                           3.0                       4   \n",
       "4                           5.0                       1   \n",
       "...                         ...                     ...   \n",
       "10128                       4.0                       1   \n",
       "10134                       3.0                       3   \n",
       "10135                       6.0                       3   \n",
       "10136                       6.0                       1   \n",
       "10145                       6.0                       3   \n",
       "\n",
       "       Contacts_Count_12_mon  Credit_Limit  Total_Revolving_Bal  \\\n",
       "0                          3       12691.0                  777   \n",
       "1                          2        8256.0                  864   \n",
       "2                          0        3418.0                    0   \n",
       "3                          1        3313.0                 2517   \n",
       "4                          0        4716.0                    0   \n",
       "...                      ...           ...                  ...   \n",
       "10128                      3        2179.0                    0   \n",
       "10134                      1        4065.0                 2180   \n",
       "10135                      2        3068.0                 1765   \n",
       "10136                      3        1438.3                    0   \n",
       "10145                      3        9881.0                 1794   \n",
       "\n",
       "       Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  Total_Trans_Ct  \\\n",
       "0                     1.335             1144              42   \n",
       "1                     1.541             1291              33   \n",
       "2                     2.594             1887              20   \n",
       "3                     1.405             1171              20   \n",
       "4                     2.175              816              28   \n",
       "...                     ...              ...             ...   \n",
       "10128                 0.725             2568              48   \n",
       "10134                 0.321             1271              36   \n",
       "10135                 0.853             4611              73   \n",
       "10136                 0.707             4733              89   \n",
       "10145                 0.582             4725              85   \n",
       "\n",
       "       Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Unnamed: 19  \n",
       "0                    1.625                  0.061          NaN  \n",
       "1                    3.714                  0.105          NaN  \n",
       "2                    2.333                  0.000          NaN  \n",
       "3                    2.333                  0.760          NaN  \n",
       "4                    2.500                  0.000          NaN  \n",
       "...                    ...                    ...          ...  \n",
       "10128                0.297                  0.000          NaN  \n",
       "10134                0.200                  0.536          NaN  \n",
       "10135                0.698                  0.575          NaN  \n",
       "10136                0.816                  0.000          NaN  \n",
       "10145                0.735                  0.182          NaN  \n",
       "\n",
       "[10132 rows x 20 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('../data/CreditPrediction.csv')\n",
    "# removing duplicated datas\n",
    "data_no_dup = data_df.drop_duplicates() \n",
    "# data_no_dup = data_no_dup.fillna(0)\n",
    "# data_no_dup = pd.get_dummies(data_no_dup, columns=['Gender', 'Education_Level', 'Marital_Status', 'Income_Category', 'Card_Category'], drop_first=True, )\n",
    "\n",
    "data_no_dup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_missing_values(df):\n",
    "    # Identify numerical and categorical columns\n",
    "    num_cols = df.select_dtypes(exclude='object').columns\n",
    "    cat_cols = df.select_dtypes(include='object').columns\n",
    "\n",
    "    # Create transformers for numerical and categorical data\n",
    "    num_transformer = IterativeImputer()\n",
    "    cat_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Combine transformers into a ColumnTransformer\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', num_transformer, num_cols),\n",
    "            ('cat', cat_transformer, cat_cols)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Apply the transformations\n",
    "    preprocessed_data = preprocessor.fit_transform(data_no_dup)\n",
    "\n",
    "    # Convert the result back to a DataFrame (optional)\n",
    "    preprocessed_df = pd.DataFrame(preprocessed_data)\n",
    "\n",
    "    # Display the preprocessed DataFrame\n",
    "    return preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kianoosh\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\impute\\_base.py:597: UserWarning: Skipping features without any observed values: [13]. At least one non-missing value is needed for imputation with strategy='mean'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X = data_no_dup.drop('Credit_Limit', axis=1)\n",
    "y = data_no_dup['Credit_Limit']\n",
    "\n",
    "X = fix_missing_values(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# feature selection\n",
    "def select_features(X_train, y_train, X_test):\n",
    " # configure to select all features\n",
    " fs = SelectKBest(score_func=mutual_info_regression, k=26)\n",
    " # learn relationship from training data\n",
    " fs.fit(X_train, y_train)\n",
    " # transform train input data\n",
    " X_train_fs = fs.transform(X_train)\n",
    " # transform test input data\n",
    " X_test_fs = fs.transform(X_test)\n",
    " return X_train_fs, X_test_fs, fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kianoosh\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\sklearn\\utils\\validation.py:1310: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset\n",
    "# split into train and test sets\n",
    "# feature selection\n",
    "X_train_fs, X_test_fs, fs = select_features(X_train, y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 0: 0.003698\n",
      "Feature 1: 0.025399\n",
      "Feature 2: 0.050603\n",
      "Feature 3: 0.031632\n",
      "Feature 4: 0.057239\n",
      "Feature 5: 0.073621\n",
      "Feature 6: 0.058978\n",
      "Feature 7: 0.156111\n",
      "Feature 8: 0.021971\n",
      "Feature 9: 0.124276\n",
      "Feature 10: 0.073115\n",
      "Feature 11: 0.014763\n",
      "Feature 12: 0.803262\n",
      "Feature 13: 0.228071\n",
      "Feature 14: 0.228529\n",
      "Feature 15: 0.140301\n",
      "Feature 16: 0.145474\n",
      "Feature 17: 0.098656\n",
      "Feature 18: 0.121454\n",
      "Feature 19: 0.139515\n",
      "Feature 20: 0.132446\n",
      "Feature 21: 0.121434\n",
      "Feature 22: 0.142566\n",
      "Feature 23: 0.105316\n",
      "Feature 24: 0.118416\n",
      "Feature 25: 0.148179\n",
      "Feature 26: 0.196802\n",
      "Feature 27: 0.156184\n",
      "Feature 28: 0.144025\n",
      "Feature 29: 0.183886\n",
      "Feature 30: 0.258041\n",
      "Feature 31: 0.150099\n",
      "Feature 32: 0.240529\n",
      "Feature 33: 0.176022\n",
      "Feature 34: 0.146098\n",
      "Feature 35: 0.218604\n",
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# what are scores for the features\n",
    "ignr_cnt = 0\n",
    "for i in range(len(fs.scores_)):\n",
    " if (fs.scores_[i] < 0.0015):\n",
    "  ignr_cnt +=1\n",
    " print('Feature %d: %f' % (i, fs.scores_[i]))\n",
    "print(ignr_cnt)\n",
    "# plot the scores\n",
    "plt.bar([i for i in range(len(fs.scores_))], fs.scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs = np.array(X_train_fs) \n",
    "X_test_fs = np.array(X_test_fs) \n",
    "\n",
    "y_train = np.array(y_train) \n",
    "y_test = np.array(y_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_fs = torch.from_numpy(X_train_fs.astype(np.float32))\n",
    "X_test_fs = torch.from_numpy(X_test_fs.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "_, n_features = X_train_fs.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.linear2 = nn.Linear(hidden_size, int(hidden_size/2))\n",
    "        self.linear3 = nn.Linear(int(hidden_size/2), int(hidden_size/4))\n",
    "        self.linear4 = nn.Linear(int(hidden_size/4), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear4(out)\n",
    "        # out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[159], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mModel2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[156], line 3\u001b[0m, in \u001b[0;36mModel2.__init__\u001b[1;34m(self, input_size, hidden_size)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_size, hidden_size):\n\u001b[1;32m----> 3\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear1 \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(input_size, hidden_size)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mReLU()\n",
      "\u001b[1;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "model = Model(n_features , 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1000, loss = 32840698.0000\n",
      "epoch: 2000, loss = 29954936.0000\n",
      "epoch: 3000, loss = 28071990.0000\n",
      "epoch: 4000, loss = 26444748.0000\n",
      "epoch: 5000, loss = 24917020.0000\n",
      "epoch: 6000, loss = 23516480.0000\n",
      "epoch: 7000, loss = 22342314.0000\n",
      "epoch: 8000, loss = 21393666.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[160], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Backward pass and update\u001b[39;00m\n\u001b[0;32m     23\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 24\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# zero grad before new step\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kianoosh\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\optimizer.py:391\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    387\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    388\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    389\u001b[0m             )\n\u001b[1;32m--> 391\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    394\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Kianoosh\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\Kianoosh\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\adam.py:168\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    157\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    159\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    160\u001b[0m         group,\n\u001b[0;32m    161\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    165\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    166\u001b[0m         state_steps)\n\u001b[1;32m--> 168\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Kianoosh\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\adam.py:318\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    316\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 318\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Kianoosh\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\optim\\adam.py:394\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    392\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    393\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mlerp_(grad, \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[1;32m--> 394\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable \u001b[38;5;129;01mor\u001b[39;00m differentiable:\n\u001b[0;32m    397\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 1000000\n",
    "learning_rate = 0.001\n",
    "criterion = nn.MSELoss()  ####################################################################\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "lambda_reg = 0.01\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass and loss\n",
    "    y_pred = model(X_train_fs)\n",
    "    loss = criterion(y_pred, y_train)\n",
    "\n",
    "    # # Compute L2 regularization term\n",
    "    l2_reg = torch.tensor(0.)\n",
    "    for param in model.parameters():\n",
    "        l2_reg += torch.norm(param)\n",
    "    \n",
    "    # Add regularization term to loss\n",
    "    loss += lambda_reg * l2_reg\n",
    "\n",
    "    # Backward pass and update\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # zero grad before new step\n",
    "\n",
    "    if (epoch+1) % 1000 == 0:\n",
    "        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42627244.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "with torch.no_grad():\n",
    "    y_predicted = model(X_test_fs)\n",
    "    # y_predicted = np.array(y_predicted)\n",
    "     \n",
    "    MSE = mean_squared_error(y_predicted, y_test)\n",
    "MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
